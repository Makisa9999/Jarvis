chatgpt_interface.py

'''
from dotenv import load_dotenv
from datetime import datetime

import openai
import os
import json

load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MAX_TURNS = 10
SYSTEM_MSG = {
    "role": "system",
    "content": "You are Jarvis, a voice-activated assistant for 3D printing, file management, and daily tasks. Be concise and useful. I am going to use you in order to show on a display what is being print on the 3D printer and managing the queue. Further you will help me find 3D models online of things that I want to print."
}

def generate_history_filename():
    now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    return f"chat_history_{now}.json"

HISTORY_FILE = generate_history_filename()
open(HISTORY_FILE, "a")

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r") as f:
            try:
                content = f.read().strip()
                if content:
                    return json.loads(content)
            except json.JSONDecodeError:
                pass
    return [SYSTEM_MSG]

def save_history(history):
    with open(HISTORY_FILE, "w") as f:
        json.dump(history, f, indent=2)

def get_chatgpt_response(prompt):
    history = load_history()
    history.append({"role":"user", "content":prompt})
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo", 
            messages=history
        ) 
        reply = response.choices[0].message.content.strip()
        history.append({"role":"assistant", "content":reply})
        if len(history) > 2 * MAX_TURNS + 1:
            history = [SYSTEM_MSG] + history[-2 * MAX_TURNS:]
        save_history(history)
        return reply
    except Exception as e:
        return f"Error: {str(e)}"
   
    # print("Thinking...")
    # response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role":"user", "content": prompt}])
    # return response.choices[0].message.content.strip()
'''

log.py
'''
from datetime import datetime

LOG_FILE = f"chat_log_{datetime.now().strftime('%Y-%m-%d_%H_%M_%S')}.txt"

def log_interaction(user_input, jarvis_response, log_file=LOG_FILE):
    now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    with open(log_file, "a") as f:
        f.write(f"\n[{now}]\n")
        f.write(f"You: {user_input}\n")
        f.write(f"Jarvis: {jarvis_response}\n")
'''

main.py
'''
from recorder import listen_for_command
from speak_text import speak_text
from vosk import Model, KaldiRecognizer

import json

model = Model("vosk-model-small-en-us-0.15")
commands = ["hey jarvis", "okay jarvis"]
rec = KaldiRecognizer(model, 16000, json.dumps(commands))

if __name__ == "__main__":
    print("Starting J.A.R.V.I.S. WELCOME...")
    while True:
        try:
            listen_for_command(rec, commands)
        except Exception as e:
            print("Error: ", e)
            speak_text("Sorry, I encountered an error.")
'''

recorder.py
'''
from scipy.io.wavfile import write
from whisper_transcriber import transcribe_audio
from utilities import downsample
from chatgpt_interface import get_chatgpt_response
from speak_text import speak_text
from log import log_interaction

import sounddevice as sd
import numpy as np

import scipy.signal
import os
import json
import tempfile

def listen_for_command(rec, commands):
	print("Listening for wake up word...")
	fs = 44100
	silence_threshold = 500
	silence_duration = 1.5
	blocksize = 1024
	silence_limit = int(silence_duration * fs / blocksize)
	sd.default.device = (2,2)
	with sd.InputStream(samplerate = fs, channels = 1, dtype = 'int16') as stream:
		while True:
			data, _ = stream.read(2048)
			audio_np = np.squeeze(data).astype(np.float32)
			audio_16k = downsample(audio_np, fs, 16000).astype(np.int16).tobytes()
			if rec.AcceptWaveform(audio_16k):
				result = json.loads(rec.Result())
				text = result.get("text", "")
				print("Heard: ", text)
				if text in commands:
					print("Recognized command: ", text)
					response_audio = []
					silence_blocks = 0
					while True:
						data, _ = stream.read(blocksize)
						block_np = np.squeeze(data).astype(np.float32)
						response_audio.append(block_np)
						amplitude = np.linalg.norm(block_np)
						if amplitude < silence_threshold:
							silence_blocks += 1
						else:
							silence_blocks = 0
						if silence_blocks > silence_limit:
							print("Silence detected, stopping...")
							break
					audio_response = np.concatenate(response_audio).astype(np.int16)
					temp_file = tempfile.NamedTemporaryFile(delete = False, suffix=".wav")
					write(temp_file.name, fs, audio_response)
					user_text = transcribe_audio(temp_file.name)
					print("You said: ", user_text)
					response = get_chatgpt_response(user_text)
					log_interaction(user_text, response)
					print("Jarvis: ", response)
					speak_text(response)
					print("Returning to listening mode only...")
'''

speak_text.py
'''
import pyttsx3

def speak_text(input):
    engine = pyttsx3.init()
    engine.setProperty('voice', 'english+m3')
    engine.setProperty('rate', 150)
    engine.setProperty('volume', 1.0)
    engine.say(input)
    engine.runAndWait()
'''

utilities.py
'''
import scipy.signal

def downsample(audio, original_rate, target_rate):
	number_of_samples = round(len(audio) * float(target_rate) / original_rate)
	return scipy.signal.resample(audio, number_of_samples)
'''

whisper_transcriber.py
'''
import openai
from dotenv import load_dotenv
import os

load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def transcribe_audio(file_path):
    print("Transcribing...")
    try:
        with open(file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
        return transcript.text
    except Exception as e:
        return f"[Whisper Error: {str(e)}]"
'''

/g_code_commands/send_gcode.py
'''
import serial
import time

def send_gcode_file(serial_port, baud_rate, gcode_file):
	try:
		ser = serial.Serial()
		ser.port = serial_port
		ser.baudrate = baud_rate
		ser.timeout = 1
		ser.dtr = False
		ser.rts = False
		ser.open()
		time.sleep(2)
		with open(gcode_file, 'r') as file:
			for line in file:
				cmd = line.strip()
				if cmd and not cmd.startswith(';'):
					ser.write((cmd + '\n').encode())
					print(f"Sent: {cmd}")
					time.sleep(0.2)
					while ser.in_waiting:
						response = ser.readline().decode().strip()
						if response:
							print(f"Printer: {response}")
		ser.close()
		print("Done sending G-code.")
	except Exception as e:
		print(f"Error: {e}")
'''

in /g_code_commands folder there are start_up.gcode, end.gcode, and bed_leveing_helper.gcode